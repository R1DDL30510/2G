# Release Report: v2025.09.16

## Release Summary
- Status: Infrastructure hardening continues; CI now exercises container bring-up in CPU mode, context sweeps, and evidence capture while GPU validation remains outstanding.
- Scope: Modelfile portability, containerised benchmarking, profile-driven sweeps, and GitHub Actions extensions for health probes and diagnostics.
- Audit Window: 17 Sep 2025 (local verification on Windows 11 Pro for Workstations with Docker 28.4.0 and dual RTX GPUs; CI confirmation on ubuntu-latest without NVIDIA runtime).

## Validation & Coverage Overview
- Automated Checks: `pytest` configuration smoke tests and new Pester script checks run locally; the `smoke-tests` workflow now boots the stack with `infra/compose/docker-compose.ci.yml`, probes Ollama/Qdrant/Open WebUI, executes a CPU-baseline context sweep, and archives capture-state evidence.
- Manual Checks: GPU-enabled sweeps and telemetry scrapes still require an operator run; the repo now ships baseline artifacts (`docs/ENVIRONMENT.md`, `docs/evidence/environment/`, `docs/evidence/ci/`).
- Risk Notes: Until CUDA sweeps and long-running benchmarks land in evidence, treat this build as pre-production.

## Issues & Resolutions
- Resolved: GPU enablement now runs through `./scripts/model.ps1 create-all`, which provisions `llama31-8b-gpu` alongside the long-context variants and accepts `-MainGpu` overrides.
- Resolved: `scripts/clean/bench_ollama.ps1` executes benchmarks inside the Ollama container, eliminating the host binary dependency and persisting artifacts under `docs/evidence/benchmarks/`.
- Resolved: `scripts/context-sweep.ps1` introduces selectable profiles (`llama31-long`, `qwen3-balanced`, `cpu-baseline`) with single-GPU defaults to prevent brownouts.
- Open: Compose images remain pinned (`ollama/ollama:0.3.11`, `ghcr.io/open-webui/open-webui:v0.6.30`, `qdrant/qdrant:v1.15.4`); track upstream CVEs prior to upgrades.
- Open: GPU evidence is still pending; CI captures CPU-only sweeps and host state but CUDA telemetry must precede production promotion.
- Watchlist: Qdrant persistence depends on existing `data/qdrant` volume; ensure backups before pruning containers.

## Dependency & Image Matrix
- Ollama Runtime: `ollama/ollama:0.3.11` (GPU-enabled; volumes mapped to `models/` cache and `modelfiles/`).
- Open WebUI: `ghcr.io/open-webui/open-webui:v0.6.30` (auth toggle via `OPENWEBUI_AUTH`).
- Qdrant Vector DB: `qdrant/qdrant:v1.15.4` storing data under `data/qdrant`.
- Scripts: PowerShell helpers under `scripts/` (compose, model lifecycle, evaluation, capture, benchmarking).
- NVIDIA Toolkit: Accessed via container runtime; ensure host drivers match CUDA requirements (no container image modifications in this release).

## Configuration Snapshot
- Environment Variables: ports `WEBUI_PORT=3000`, `OLLAMA_PORT=11434`, `QDRANT_PORT=6333`; storage paths `MODELS_DIR=./models`, `DATA_DIR=./data`; authentication flag `OPENWEBUI_AUTH=false` (toggle before exposing beyond localhost).
- Compose Overrides: `infra/compose/docker-compose.yml` now defaults to CPU mode; layer `infra/compose/docker-compose.gpu.yml` to request NVIDIA resources, while CI continues to apply `infra/compose/docker-compose.ci.yml` for headless CPU runs.
- Network Bindings: Localhost endpoints â€” WebUI `3000/tcp`, Ollama `11434/tcp`, Qdrant `6333/tcp`.
- Persistence: Model cache under `models/` (git-ignored), service state under `data/` with directory-per-service segmentation.

## Operational Checklist
1. Bootstrap environment file: `./scripts/bootstrap.ps1 -PromptSecrets` to copy `.env`, create directories, and regenerate `docs/ENVIRONMENT.md` on a fully provisioned host.
2. Start stack: `./scripts/compose.ps1 up` (uses `infra/compose/docker-compose.yml`).
3. Verify services: `./scripts/compose.ps1 logs` or `docker compose -f infra/compose/docker-compose.yml ps`, then run `curl` against Ollama (`/api/version`), Open WebUI (`http://localhost:3000`), and Qdrant (`/collections`).
4. Model management: `./scripts/model.ps1 create-all -MainGpu <index>` provisions all context variants and `llama31-8b-gpu`; confirm with `./scripts/model.ps1 list` and archive the output.
5. Evaluation: `./scripts/context-sweep.ps1 -Safe -Profile llama31-long -WriteReport` for CUDA hosts, or switch to `cpu-baseline` in constrained environments. Store outputs under `docs/evidence/`.
6. Benchmarking: `./scripts/clean/bench_ollama.ps1 -Iterations 3` now pushes prompts through the running container; include reports in release notes.

## Next Steps
- Schedule GPU-backed context sweeps prior to tagging releases and capture the resulting Markdown/JSON evidence.
- Extend CI with a GPU matrix when runners are available, mirroring the CPU flow introduced in `smoke-tests.yml`.
- Expand Pester coverage to exercise PowerShell menu flows (`./scripts/bootstrap.ps1 -Menu`) and Ollama benchmarking edge cases.
- Document and rehearse recovery procedures for Qdrant and WebUI volumes, alongside GPU telemetry collection during inference runs.
- Establish a cadence to review pinned image tags and apply security updates after validation.