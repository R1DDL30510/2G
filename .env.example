# Ports
WEBUI_PORT=3000
OLLAMA_PORT=11434
QDRANT_PORT=6333

# Paths (relative to repo root)
MODELS_DIR=./models
DATA_DIR=./data

# WebUI config
OPENWEBUI_AUTH=false

# CLI integration (Codex, etc.)
OLLAMA_API_KEY=ollama-local

# Diagnostics and benchmarking
# Context sweep defaults
CONTEXT_SWEEP_PROFILE=llama31-long
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_BENCH_MODEL=llama3.1:8b
OLLAMA_BENCH_PROMPT=./docs/prompts/bench-default.txt
EVIDENCE_ROOT=./docs/evidence

# GPU routing defaults
OLLAMA_VISIBLE_GPUS=1
OLLAMA_GPU_ALLOCATION=device=1

# Logging
LOG_FILE=./logs/stack.log
